import requests, json, time, codecs, re, sys, getopt
from helper_funcs import *
from db_ops import *
from prometheus_client.core import CollectorRegistry, GaugeMetricFamily, REGISTRY, CounterMetricFamily, Gauge
from prometheus_client import start_http_server
from os.path import isfile, dirname, exists
from os import getcwd

def increment_metric_state(gauge_name, key):
    """
    Increments a metric in data_obj by 1

    Parameters:
    -----------
    gauge_name : str
        The name of the metric to increment
    key : str / hex
        The public key of the associated validator
    """
    global data_obj

    # first checks if entry exists
    if key not in data_obj["latest_metrics"][gauge_name]:
        data_obj["latest_metrics"][gauge_name][key] = 0

    data_obj["latest_metrics"][gauge_name][key] += 1

def init_metric_state(gauge_name, key):
    """
    Initliases a metric in data_obj by setting it to 0

    Parameters:
    -----------
    gauge_name : str
        The name of the metric to initialise
    key : str / hex
        The public key of the associated validator
    """
    global data_obj

    data_obj["latest_metrics"][gauge_name][key] = 0

def increment_blocks_proposed(public_key, relay):
    """
    Increments respective metrics when a validator proposes a new block

    Parameters:
    -----------
    public_key : str / hex
        The public key of the validator that proposed the block
    relay : str
        The name of the relay through which the block was relayed
    """
    global relay_blocks_gauge, validator_totals_gauge

    relay_blocks_gauge.labels(relay).inc()
    increment_metric_state("RelayBlocksProposed", relay)
    validator_totals_gauge.labels(public_key).inc() 
    increment_metric_state("ValidatorBlocksProposed", public_key)

def update_validator_reward_metrics(relayer, reward):
    """
    Updates metrics related to rewards incurred by validators we are monitoring

    Parameters:
    -----------
    relay : str
        The name of the relay through which the block was relayed, or 'Unknown' otherwise
    reward : float
        The reward incurred by proposing the block
    """
    global val_total_rewards_gauge, val_avg_reward_gauge, val_unknown_reward_blocks, data_obj

    # if the reward is unknown
    if reward == -1:
        # update the number of blocks with unknown rewards
        val_unknown_reward_blocks.labels(relayer).inc()
        update_relayer_metric_state("ValUnknownRewardBlocks", relayer, 1)
    else:
        # update the total rewards generated by our validators by using this relayer
        val_total_rewards_gauge.labels(relayer).inc(reward)
        update_relayer_metric_state("TotalValidatorRewards", relayer, reward)

        # check if calculation results in 0 first
        if (data_obj["latest_metrics"]["RelayBlocksProposed"][relayer] - data_obj["latest_metrics"]["ValUnknownRewardBlocks"][relayer]) != 0:
            # update average reward of our validators using this specific relayer
            avg = data_obj["latest_metrics"]["TotalValidatorRewards"][relayer] / (data_obj["latest_metrics"]["RelayBlocksProposed"][relayer] - data_obj["latest_metrics"]["ValUnknownRewardBlocks"][relayer])
            val_avg_reward_gauge.labels(relayer).set(avg)
            update_relayer_metric_state("AvgValidatorRewards", relayer, avg, False)
        

def increment_missed_blocks(public_key):
    """
    Increments missed blocks metric

    Parameters:
    -----------
    public_key : str / hex
        The public key of the validator that missed the block
    """
    global missed_gauge

    increment_metric_state("MissedBlockProposals", public_key)
    missed_gauge.labels(public_key).inc() 

def increment_empty_blocks(public_key):
    """
    Increments empty blocks metric

    Parameters:
    -----------
    public_key : str / hex
        The public key of the validator that missed the block
    """
    global empty_gauge

    increment_metric_state("EmptyBlockProposals", public_key)
    empty_gauge.labels(public_key).inc() 

def update_relayer_metric_state(gauge_name, relayer, amount, increment=True):
    """
    Updates relayer metric depending on parameters

    Parameters:
    -----------
    gauge_name : str
        The name of the metric to update
    relayer : str
        The associated relayer to update the metric for
    amount : float
        The amount to update the metric by
    increment : bool
        Whether to increment the metric by the amount (True/default) or to set the metric as the amount (False)
    """
    global data_obj

    if increment:
        data_obj["latest_metrics"][gauge_name][relayer] += amount
    else:
        data_obj["latest_metrics"][gauge_name][relayer] = amount

def update_reward_metrics(relayer, reward):
    """
    Updates relayer reward metrics

    Parameters:
    -----------
    relayer : str
        The name of the relayer to update metrics for
    reward : float
        The reward generated by the relayer
    """
    global total_relay_blocks_gauge, total_rewards_gauge, avg_reward_gauge, unknown_reward_blocks, data_obj
    
    # if the reward is unknown
    if reward == -1:
        # update the number of blocks with unknown rewards
        unknown_reward_blocks.labels(relayer).inc()
        update_relayer_metric_state("UnknownRewardsBlocks", relayer, 1)

        # update the number of blocks relayed by relayer
        total_relay_blocks_gauge.labels(relayer).inc()
        update_relayer_metric_state("TotalRelayBlocksProposed", relayer, 1)
    # if reward value is known
    else:
        # update the number of blocks relayed by relayer
        total_relay_blocks_gauge.labels(relayer).inc()
        update_relayer_metric_state("TotalRelayBlocksProposed", relayer, 1)

        # update the total rewards generated by using this relayer
        total_rewards_gauge.labels(relayer).inc(reward)
        update_relayer_metric_state("RelayTotalRewards", relayer, reward)

        # check if calculation results in 0, so we don't divide by 0
        if (data_obj["latest_metrics"]["TotalRelayBlocksProposed"][relayer] - data_obj["latest_metrics"]["UnknownRewardsBlocks"][relayer]) != 0:
            # update average reward of using specific relayer
            avg = data_obj["latest_metrics"]["RelayTotalRewards"][relayer] / (data_obj["latest_metrics"]["TotalRelayBlocksProposed"][relayer] - data_obj["latest_metrics"]["UnknownRewardsBlocks"][relayer])
            avg_reward_gauge.labels(relayer).set(avg)
            update_relayer_metric_state("AvgRelayerRewards", relayer, avg, False)

def get_epoch_from_slot(slot) -> int:
    """
    Calculates the epoch number from the slot number

    Parameters:
    -----------
    slot : int
        The slot number

    Returns:
    --------
    int
        The epoch that the slot is in
    """
    # there are 32 slots in each epoch
    return slot // 32

def get_slot_proposer(slot):
    """
    Gets the public key of the block proposer for the given slot

    Parameters:
    -----------
    slot : int
        The slot number

    Returns:
    --------
    str / hex
        The public key of the block proposer (validator) for the slot given
    """
    global config, retries

    epoch = get_epoch_from_slot(slot)

    s = requests.Session()
    s.mount('http://', HTTPAdapter(max_retries=retries))

    # get duties for epoch (block proposers)
    duties = s.get(eth2_rpc+"/eth/v1/validator/duties/proposer/"+str(epoch), timeout=45).json()
    for duty in duties["data"]:
        if duty["slot"] == str(slot):
            # return the public key of the validator for that slot
            return duty["pubkey"]

def check_duties(slot):
    """
    Checks if we can start gathering data from the slot passed by attempting to check duties for the slot's epoch.

    Parameters:
    -----------
    slot : int
        The slot number

    Returns:
    --------
    int
        0: check succeeds and we can gather data from the slot passed onwards
        -1: check failed and slot is too behind to get data
        any other slot number: check failed, and the slot number returned is the largest possible to start from
    """
    global config

    epoch = get_epoch_from_slot(slot)

    s = requests.Session()
    temp_retries = Retry(total=10, backoff_factor=0.00005, status_forcelist=[503, 504], allowed_methods=frozenset(['GET', 'POST']))
    s.mount('http://', HTTPAdapter(max_retries=temp_retries))

    # try to get duties for given epoch
    duties = s.get(eth2_rpc+"/eth/v1/validator/duties/proposer/"+str(epoch), timeout=45).json()

    if 'data' in duties:
        # if we have data, then we can proceed
        return 0
    elif 'code' in duties:
        # if there is a status code, then the request failed
        if duties['code'] == 500:
            # try to get the range to let the user know what slot they can start from
            if 'message' in duties:
                range = re.findall(r'\b\d+\b', duties['message'])
                range_ints = [int(x) for x in range]
                return max(range_ints)
    
    # if we failed and cannot get range for user, return -1
    return -1

def get_current_slot() -> int:
    """
    Gets the latest slot number from the Beacon Chain RPC

    Returns:
    --------
    int
        The latest slot number
    """
    global config

    # get current slot
    s = requests.Session()
    s.mount('http://', HTTPAdapter(max_retries=retries))

    # try to return the slot number as an integer
    try:
        data = s.get(eth2_rpc+"/eth/v1/beacon/headers", timeout=60).json()
        return int(data['data'][0]['header']['message']['slot'])
    except Exception as e:
        raise Exception("Failed to get current slot (get_current_slot()): "+e)

def get_validator_indexes(public_keys: list) -> dict:
    """
    Gets the indexes of the validators from their public key using the Beacon Chain RPC

    Returns:
    --------
    dict
        A dict where the key is the public key of the validator and the value is the validator's index
    """

    # get current slot first
    curr_slot = get_current_slot()
    
    key_index = {}

    for key in public_keys:
        # get the index for each validator
        index = get_validator_index(curr_slot, key)
        key_index[key] = index
    
    return key_index

def get_validator_indexes_parallel(public_keys: list) -> dict:
    """
    Same functionality as get_validator_indexes(), but performs RPC calls parallelly

    Returns:
    --------
    dict
        A dict where the key is the public key of the validator and the value is the validator's index
    """
    global config, retries

    # get current slot first
    curr_slot = get_current_slot()

    # create the class of the worker
    class Worker(Thread):
        def __init__(self, key_queue):
            Thread.__init__(self)
            self.queue = key_queue
            self.results = []
        
        def run(self):
            # keep running until it finds an empty string
            while True:
                # get the next key in the queue
                key = self.queue.get()
                if key == "":
                    break
                try:
                    s = requests.Session()
                    s.mount('http://', HTTPAdapter(max_retries=retries))

                    # try to get the validator index
                    data = s.get(eth2_rpc+"/eth/v1/beacon/states/"+str(curr_slot)+"/validators/"+key, timeout=30).json()
                    if 'data' in data:
                        if 'index' in data['data']:
                            data = data['data']['index']
                            # if we got it, append it as a dict where the key is the public key, and the value is the index
                            self.results.append({key: data})
                            self.queue.task_done()
                        else:
                            self.results.append({key: None})
                            self.queue.task_done()
                    else:
                        self.results.append({key: None})
                        self.queue.task_done()
                except Exception as e:
                    print("WARN: ETH2 request failed - get_validator_indexes_parallel(): "+e)
                    self.results.append({key: None})
                    self.queue.task_done()
    
    num_workers = 20
    q = Queue()

    # add each key in the queue
    for key in public_keys:
        q.put(key)

    # add empty strings which will tell the workers that they're done
    for _ in range(num_workers * 2):
        q.put("")

    workers = []

    # create the workers
    for _ in range(num_workers):
        worker = Worker(q)
        worker.start()
        workers.append(worker)

    # get the results
    for worker in workers:
        worker.join()

    # store the results in an array
    results = []
    for worker in workers:
        results.extend(worker.results)

    results_dict = {}

    # go over each dict
    for dict in results:
        for key, value in dict.items():
            # if the request failed, try again
            if value is None:
                results_dict[key] = get_validator_index(curr_slot, key)
            else:
                results_dict[key] = value

    return results_dict

def get_validator_index(slot: int, key: str) -> int:
    """
    Performs an RPC call to get the index of the validator given its public key

    Parameters:
    -----------
    slot : int
        The slot number at which to check - more recent slot numbers usually results in a quicker response
    key : str
        The public key of the validator

    Returns:
    --------
    int
        The index of the validator
    """
    global config, retries

    s = requests.Session()
    s.mount('http://', HTTPAdapter(max_retries=retries))
    
    # attempt the request
    try:
        data = s.get(eth2_rpc+"/eth/v1/beacon/states/"+str(slot)+"/validators/"+key, timeout=60).json()
        if 'data' in data:
            if 'index' in data['data']:
                return data['data']['index']
        else:
            return None
    except Exception as e:
        raise Exception("Failed to get validator index (get_validator_index()): "+e)

def sync_committee_hex_to_bits(hex: str) -> list:
    """
    Converts the sync committee participation hexadecimal returned by the Beacon Chain RPC to bits

    Parameters:
    -----------
    hex : str / hex
        The sync committee participation hex

    Returns:
    --------
    list
        The participation bits as a list of 1s and 0s
    """
    # convert the hex to bytes - removing the 0x at the start
    byte_data = codecs.decode(re.sub("0x", "", hex), "hex")

    # check that we have 512 bits (since we converted to bytes, 1 byte = 8 bits), the size of the sync committee
    if len(byte_data) * 8 != 512:
        raise Exception("Length of sync committee hex is "+str(len(byte_data) * 8)+" bits, expected length is 512.")

    # create array to hold bits
    bits = []

    # iterate over the data to set bit values
    for i in range(len(byte_data) * 8):
        # get the byte that the bit is in
        byte = byte_data[i // 8]
        
        # set the bit that we want to check as 1
        # so if we want to check the 5th (i=4) bit, this would create a 00001000 byte
        test_byte = 1 << (i % 8)

        # do bitwise AND, which will result in a value greater than 1 if the bit we are checking is 1
        # example, bitwise AND of 10101100 & 00001000 results in 00001000 (decimal value of 8) because the 5th bit is 1 in both
        # whereas, bitwise AND of 11100111 & 00001000 results in 00000000 (decimal value of 0) because the 5th bit is 0 in the first byte
        # we are checking for the original byte (from byte_data), and only using test_byte to see if it is 1 or 0
        result = byte & test_byte
        
        # if result > 0 (i.e. any byte that is not 00000000), append a 1, otherwise 0
        bits.append(1 if result > 0 else 0)

    return bits

def check_sync_committee(validator_indexes: list, curr_slot: int = 0):
    """
    Populates the global variables with the current sync committee info

    Parameters:
    -----------
    validator_indexes : list
        A list of the validator indexes of our validators
    curr_slot : int
        The current slot
    """
    global config, retries, prev_sync_committee, curr_sync_committee, next_sync_committee, curr_sync_start_epoch, next_sync_start_epoch, val_sync_participated_gauge, val_sync_missed_gauge, validators_index_key_mappings, current_sync_committee_epoch_gauge, next_sync_updated

    # remove old committee metrics
    for val_index in prev_sync_committee:
        try:
            val_sync_participated_gauge.remove(validators_index_key_mappings[val_index], curr_sync_start_epoch-256)
            val_sync_missed_gauge.remove(validators_index_key_mappings[val_index], curr_sync_start_epoch-256)
        except:
            print("WARN: Failed to remove old committee metrics (check_sync_committee()).")

    try:
        current_sync_committee_epoch_gauge.remove(curr_sync_start_epoch-256)
    except:
        pass

    # check if we have a slot number, otherwise get it
    if curr_slot == 0:
        curr_slot = get_current_slot()

    # calculate the first epoch of this committee and the next epoch of the next committee from the slot number
    curr_sync_start_epoch = ((curr_slot // 32) // 256) * 256
    next_sync_start_epoch = curr_sync_start_epoch + 256

    # update current and past start epoch metrics
    current_sync_committee_epoch_gauge.labels(curr_sync_start_epoch-256).set(0)
    current_sync_committee_epoch_gauge.labels(curr_sync_start_epoch).set(1)
    
    # get the sync committees
    if curr_sync_committee != {}:
        # if this is not the first time setting these variables, set the past committee as the current
        prev_sync_committee = curr_sync_committee

    curr_sync_committee = get_validator_committee_index(validator_indexes, curr_slot//32)

    # initialise the metrics for the current committee to 0
    for val_index in curr_sync_committee:
        val_sync_participated_gauge.labels(validators_index_key_mappings[val_index], curr_sync_start_epoch).set(0)
        val_sync_missed_gauge.labels(validators_index_key_mappings[val_index], curr_sync_start_epoch).set(0)

    next_sync_updated = False

def update_next_sync_committee_metrics(validator_indexes: list):
    """
    Populates the global variables with the upcoming sync commitee info

    Parameters:
    -----------
    validator_indexes : list
        A list of the validator indexes of our validators
    """
    global next_sync_committee, next_sync_start_epoch, next_sync_updated

    next_sync_committee = get_validator_committee_index(validator_indexes, next_sync_start_epoch)

    # update upcoming sync committee metrics
    update_upcoming_sync_committee_participations(next_sync_start_epoch)
    update_upcoming_sync_committee_part_metrics(next_sync_start_epoch)

    next_sync_updated = True


def check_sync_performance_slot(slot: int = 0, slot_data: dict = {}) -> dict:
    """
    Calculates the performance of the validators in the committee for a given slot

    Parameters:
    -----------
    slot : int
        The slot number of the slot to check performance for. This parameter is ignored if slot_data is provided.
    slot_data : dict
        The JSON format of the data returned by the Beacon Chain RPC when requesting a slot. This parameter is optional if slot is provided.

    Returns:
    --------
    dict
        Returns a dict where the key is the index of the validator and the value is whether it participated in the slot or not
    """
    global curr_sync_committee
    
    # check that at least one parameter was passed
    if slot == 0 and slot_data == {}:
        raise Exception("At least one parameter must be passed (check_sync_performance_slot()).")

    # get the sync committee participation bits as hex
    hex = get_slot_sync_committee_bits(slot, slot_data)

    # check if slot is missed first (0x0)
    if hex == "0x0":
        return {}

    # convert the hex to bits
    bits = sync_committee_hex_to_bits(hex)

    performance = {}

    for val_index, sync_index in curr_sync_committee.items():
        # if the value of the committee bits at the validator's sync committee index is 1, then it participated - otherwise it missed
        performance[val_index] = bits[sync_index] == 1

    return performance

def check_sync_performance_epoch(epoch: int) -> dict:
    """
    Calculates the performance of the validators in the committee for a given epoch

    Parameters:
    -----------
    epoch : int
        The epoch to check the performance at

    Returns:
    --------
    dict
        A dict where the key is the index of the validator and the value is a dict containing:
            'Participated': the number of blocks the validator participated in
            'Missed': the number of blocks the validator did not participate in
            'MissedBlock': the number of missed blocks - the validator could not participate
    """
    global curr_sync_committee

    # check if epoch is in the future
    curr_slot = get_current_slot()
    curr_epoch = curr_slot // 32

    if epoch > curr_epoch:
        raise Exception("Cannot get sync performance for epoch which is in the future. The current epoch is "+str(curr_epoch)+", whereas the epoch requested is "+str(epoch)+".")

    # calculate first slot of requested epoch
    i = epoch * 32

    # check until which slot to check - either the first slot of the next epoch, or the current slot - to avoid querying for future slots
    last_slot = (epoch + 1) * 32 if (curr_slot + 1) > ((epoch + 1) * 32) else (curr_slot + 1)

    # store results in a dict
    validators_performance = {}

    # initialise values
    for validator in curr_sync_committee.keys():
        validators_performance[validator] = {
                    'Participated': 0,
                    'Missed': 0,
                    'MissedBlock': 0
                }

    # iterate over slots
    while i < last_slot:
        curr_performance = check_sync_performance_slot(i)

        # check if slot is missed
        if curr_performance == {}:
            for validator in curr_sync_committee.keys():
                validators_performance[validator]['MissedBlock'] += 1
        else:
            for val_index, result in curr_performance.items():
                if result:
                    validators_performance[val_index]['Participated'] += 1
                else:
                    validators_performance[val_index]['Missed'] += 1
        
        # move to next slot
        i += 1

    return validators_performance

def update_sync_committee_performance(slot: int = 0, slot_data: dict = {}):
    """
    Checks and updates the sync committee performance for the validators we are monitoring that are in the sync committee

    Parameters:
    -----------
    slot : int
        The slot to check performance at. Parameter is ignored if slot_data is provided.
    slot_data : dict
        The JSON format as returned by the Beacon Chain RPC when requesting a slot. Parameter is optional as long as slot is provided.
    """
    global validators_index_key_mappings, curr_sync_committee

    # if the current committee does not include any of our validators, return
    if curr_sync_committee == {}:
        return

    # make sure at least one parameter was passed
    if slot == 0 and slot_data == {}:
        raise Exception("At least one parameter must be passed (update_sync_committee_performance()).")

    # get performance for slot
    if slot_data != {}:
        performance = check_sync_performance_slot(slot_data=slot_data)
    else:
        performance = check_sync_performance_slot(slot=slot)

    # convert index to public key
    new_performance = {}
    for key, value in performance.items():
        new_performance[validators_index_key_mappings[key]] = value

    # update metrics
    update_sync_committee_metrics(new_performance)

    # insert in database
    if slot_data != {}:
        insert_sync_committee_performance(int(slot_data['data']['message']['slot']), performance)
    else:
        insert_sync_committee_performance(slot, performance)

def update_sync_committee_metrics(key_performance_mappings: dict):
    """
    Updates the sync committee metrics according to the passed parameter

    Parameters:
    -----------
    key_performance_mappings : dict
        A dict where the key is the public key of the validator and the value is whether it participated or not in the sync committee
    """
    global val_sync_participated_gauge, val_sync_missed_gauge, curr_sync_start_epoch

    for key, value in key_performance_mappings.items():
        # if it participated, increment the 'participated' metric by 1, otherwise increment the 'missed' metric by 1
        if value:
            val_sync_participated_gauge.labels(key, curr_sync_start_epoch).inc(1)
        else:
            val_sync_missed_gauge.labels(key, curr_sync_start_epoch).inc(1)

def set_sync_committee_metrics(participated: dict, missed: dict, epoch: int):
    """
    Sets the sync committee metrics to a given value

    Parameters:
    -----------
    participated : dict
        A dict where the key is the public key of the validator and the value is an integer indicating in how many blocks it participated
        in the sync committee for the given start epoch
    missed : dict
        A dict where the key is the public key of the validator and the value is an integer indicating how many blocks it missed in the
        sync committee for the given start epoch
    epoch : int
        The starting epoch of the sync committee
    """
    global val_sync_participated_gauge, val_sync_missed_gauge

    for key, value in participated.items():
        val_sync_participated_gauge.labels(key, epoch).set(value)
    
    for key, value in missed.items():
        val_sync_missed_gauge.labels(key, epoch).set(value)

def get_validator_committee_index(validator_indexes: list, epoch: int) -> dict:
    """
    Gets the position (index) of the validators in the committee sync. This is used to know which bit corresponds to it.

    Parameters:
    -----------
    validator_indexes : list
        A list of the indexes of the validators to look for
    epoch : int
        The epoch at which to get the sync committee

    Returns:
    --------
    dict
        Returns a dict where the key is the index of the validator and the value is its position in the sync committee
    """
    global config, retries

    # get the sync committee
    s = requests.Session()
    s.mount('http://', HTTPAdapter(max_retries=retries))

    try:
        data = s.get(eth2_rpc+"/eth/v1/beacon/states/finalized/sync_committees?epoch="+str(epoch), timeout=60).json()
        
        # convert sync committee validator indexes to int so we can compare
        sync_committee = list(map(int, data['data']['validators']))
        validator_sync_index_mapping = {}
        
        # keep a counter for the position in the committee
        i = 0

        for index in sync_committee:
            # if we found one of our validators, save the position they're in
            if index in validator_indexes:
                validator_sync_index_mapping[index] = i
            i += 1

        return validator_sync_index_mapping

    except Exception as e:
        raise Exception("Failed to get validator committee indexes (get_validator_committee_index()): "+e)

def get_slot(slot: int) -> dict:
    """
    Given a slot number, it returns the corresponding slot by using an RPC

    Parameters:
    -----------
    slot : int
        The slot number

    Returns:
    --------
    dict
        The slot as returned by the RPC
    """
    global config, retries

    # get the slot
    s = requests.Session()
    s.mount('http://', HTTPAdapter(max_retries=retries))
    try:
        data = s.get(eth2_rpc+"/eth/v2/beacon/blocks/"+str(slot)).json()
        if 'code' in data:
            if data['code'] == 500:
                raise Exception("Error from node while getting slot "+str(slot)+"\n"+data['message'])
    except Exception as e:
        raise Exception("Failed to get slot (get_slot()): "+e)

    # return the slot
    return data

def get_slot_sync_committee_bits(slot: int = 0, slot_data: dict = {}) -> str:
    """
    Given a slot number, it returns the sync committee bits as hex

    Parameters:
    -----------
    slot : int
        The slot number

    Returns:
    --------
    str / hex
        The sync committee bits as returned by the RPC
    """
    # check that at least one parameter was passed
    if slot == 0 and slot_data == {}:
        raise Exception("At least one parameter has to be passed (get_slot_sync_committee_bits()).")

    if slot_data == {}:
        # get the slot
        slot_data = get_slot(slot)

    # return the hex
    try:
        return slot_data['data']['message']['body']['sync_aggregate']['sync_committee_bits']
    except:
        # block is missed - return 0x0
        return "0x0"

def update_upcoming_block_proposals(curr_slot: int):
    """
    Updates the global variable keeping track of upcoming block proposals

    Parameters:
    -----------
    curr_slot : int
        The current / last slot number
    """
    global upcoming_proposals

    # get the upcoming block proposals
    block_proposals = get_upcoming_block_proposals(get_epoch_from_slot(curr_slot))
    block_proposals = [x for x in block_proposals if x['slot'] > curr_slot]

    # add block proposals which are not already in the list
    for proposal in block_proposals:
        if proposal not in upcoming_proposals:
            upcoming_proposals.append(proposal)

def get_upcoming_block_proposals(epoch: int) -> list:
    """
    Gets block proposals where the proposer is one of the validators it is monitoring, up to 2 epochs ahead

    Parameters:
    -----------
    epoch : int
        The epoch to start checking at. We can see at most 2 epochs ahead of the current

    Returns:
    --------
    list
        A list of dicts, where the dicts contain the public key of the proposer and the slot at which it is proposing
    """
    global config, retries, keys

    s = requests.Session()
    s.mount('http://', HTTPAdapter(max_retries=retries))

    results = []

    # try to get duties for given epoch
    duties_1 = s.get(eth2_rpc+"/eth/v1/validator/duties/proposer/"+str(epoch), timeout=45).json()

    try:
        # iterate over duties to see if we have any matching keys
        for duty in duties_1['data']:
            # if we do have a matching key, add it to the results
            if duty['pubkey'] in keys:
                results.append({
                    "pubkey": duty['pubkey'],
                    "slot": int(duty['slot'])
                })

        try:
            # try to get duties for next epoch
            duties_2 = s.get(eth2_rpc+"/eth/v1/validator/duties/proposer/"+str(epoch+1), timeout=45).json()
            
            for duty in duties_2['data']:
                if duty['pubkey'] in keys:
                    results.append({
                        "pubkey": duty['pubkey'],
                        "slot": int(duty['slot'])
                    })
            
            try:
                # & try for epoch after
                duties_3 = s.get(eth2_rpc+"/eth/v1/validator/duties/proposer/"+str(epoch+2), timeout=45).json()

                for duty in duties_3['data']:
                    if duty['pubkey'] in keys:
                        results.append({
                            "pubkey": duty['pubkey'],
                            "slot": int(duty['slot'])
                        })
            except:
                return results
        except:
            return results
    except:
        return results
    
    return results

def update_upcoming_sync_committee_participations(epoch: int):
    """
    Updates the global variable keeping track of upcoming sync committee participations

    Parameters:
    -----------
    epoch : int
        The first (or any) epoch of the next sync committee
    """
    global upcoming_sync_committee

    # get the upcoming participations
    participants = get_upcoming_sync_committee_participations(epoch)

    # add block proposals which are not already in the list
    for participant in participants:
        if participant not in upcoming_sync_committee:
            upcoming_sync_committee.append(participant)

def get_upcoming_sync_committee_participations(epoch: int) -> list:
    global config, retries, validators_index_key_mappings

    s = requests.Session()
    s.mount('http://', HTTPAdapter(max_retries=retries))

    results = []

    # try to get sync committee for epoch provided
    data = s.get(eth2_rpc+"/eth/v1/beacon/states/finalized/sync_committees?epoch="+str(epoch), timeout=60).json()

    try:
        # convert sync committee validator indexes to int so we can compare
        sync_committee = list(map(int, data['data']['validators']))
        
        for index in sync_committee:
            if index in list(validators_index_key_mappings.keys()):
                results.append({
                        "pubkey": validators_index_key_mappings[index],
                        "epoch": epoch
                    })
        
        return results
    except:
        return results

def update_block_prop_metrics(last_slot: int):
    """
    Creates the relevant metrics related to upcoming block proposals

    Parameters:
    -----------
    last_slot : int
        The current / last slot number
    """
    global upcoming_block_prop_gauge, upcoming_proposals

    # remove metrics where the slot number is smaller than the current
    upcoming_proposals = [x for x in upcoming_proposals if check_proposal(x, last_slot)]

    # create metrics for upcoming block proposals
    for proposal in upcoming_proposals:
        upcoming_block_prop_gauge.labels(proposal['pubkey']).set(proposal['slot'])

def check_proposal(proposal: dict, last_slot: int) -> bool:
    """
    Checks if a block proposal is upcoming or in the past, and removes the metric accordingly

    Parameters:
    -----------
    proposal : dict
        A dict containing the public key of the proposer, and the slot at which it is proposing

    Returns:
    --------
    bool
        Whether the proposal is in the future or not
    """
    global upcoming_block_prop_gauge
    
    # if proposal is older than the current slot, then we need to remove it
    if proposal['slot'] <= last_slot:
        try:
            # remove its metric and indicate it should be removed from the list as well
            upcoming_block_prop_gauge.remove(proposal['pubkey'])
        except:
            pass
        return False
    
    # if proposal is in the future, we keep it
    return True

def update_upcoming_sync_committee_part_metrics(epoch: int):
    """
    Creates the relevant metrics related to upcoming sync committee participation

    Parameters:
    -----------
    epoch : int
        
    """
    global upcoming_sync_comm_part_gauge, upcoming_sync_committee

    # remove metrics where the epoch number is smaller than the current
    upcoming_sync_committee = [x for x in upcoming_sync_committee if check_participant(x, epoch)]

    # create metrics for upcoming sync committee participation
    for participant in upcoming_sync_committee:
        upcoming_sync_comm_part_gauge.labels(participant['pubkey']).set(participant['epoch'])

def check_participant(participant: dict, epoch: int) -> bool:
    """
    Checks if a sync participant is in the future or not, and removes the corresponding metric accordingly

    Parameters:
    -----------
    participant : dict
        A dict containing the public key of the participant and the starting epoch of its participation

    Returns:
    --------
    bool
        Whether the participation is in the future (upcoming) or not
    """
    global upcoming_sync_comm_part_gauge
    
    # if proposal is older than the current slot, then we need to remove it
    if participant['epoch'] < epoch:
        try:
            # remove its metric and indicate it should be removed from the list as well
            upcoming_sync_comm_part_gauge.remove(participant['pubkey'])
        except:
            pass
        return False
    
    # if proposal is in the future, we keep it
    return True

def check_if_empty(slot):
    """
    Checks if a given slot/block has no transactions i.e. is empty

    Parameters:
    -----------
    slot : int
        The slot number

    Returns:
    --------
    bool
        Whether the block is empty (True) or not (False)
    """
    # get the transactions in the given block
    block = get_slot(slot)
    try:
        txs = block["data"]["message"]["body"]["execution_payload"]["transactions"]
    except:
        return False

    # if there are none, then it is empty
    return len(txs) == 0

def update_metrics(data, reward=None):
    """
    Updates metrics related to blocks proposed

    Parameters:
    -----------
    data : object
        Object containing information about the slot, most importantly the public key of the proposer, and the relay used
    """
    global keys, reward_metrics

    # check if proposer is in our list of keys
    if data["proposer"] in keys:
        if data["missed"]:
            # if we missed the block, update the metric
            increment_missed_blocks(data["proposer"])
            if data["empty"]:
                increment_empty_blocks(data["proposer"])
        elif data["empty"]:
            # if the block is empty, update the metric
            increment_empty_blocks(data["proposer"])
        else:
            # otherwise update the other metrics
            increment_blocks_proposed(data["proposer"], data["relay"])
            
            if reward_metrics:
                update_validator_reward_metrics(data["relay"], reward)

def init_metrics_to_zero(gauge, gauge_dict):
    """
    Initialises the metric passed to 0 for all public keys, except for those in the dictionary. Certain metrics are being monitored
    through increase() in the Grafana dashboard, which means they must have an initial value of 0 in order to be detected

    Parameters:
    -----------
    gauge : Gauge object
        The gauge object of the metric to initialise
    gauge_dict : dict
        Dict containing the values which are not 0. The key is the public key of the validator, and the value is the value of that metric
    """
    global keys

    # first set the metrics for which we have an actual value
    for key, value in gauge_dict.items():
        gauge.labels(key).set(value)
    
    # then initialise the metrics for those that we do not have a value
    for key in keys:
        if key not in gauge_dict:
            gauge.labels(key).set(0)


def load_metrics(metrics_state):
    """
    Updates the prometheus metrics to match the ones passed

    Parameters:
    -----------
    metrics_state : object
        Object containing the different metrics as a dictionary
    """
    global relay_blocks_gauge, total_relay_blocks_gauge, total_rewards_gauge, avg_reward_gauge, unknown_reward_blocks, validator_totals_gauge, missed_gauge, empty_gauge, reward_metrics, val_total_rewards_gauge, val_avg_reward_gauge, val_unknown_reward_blocks

    for key in metrics_state["RelayBlocksProposed"]:
        relay_blocks_gauge.labels(key).set(metrics_state["RelayBlocksProposed"][key]) 

    for key in metrics_state["TotalRelayBlocksProposed"]:
        total_relay_blocks_gauge.labels(key).set(metrics_state["TotalRelayBlocksProposed"][key])

    init_metrics_to_zero(validator_totals_gauge, metrics_state["ValidatorBlocksProposed"])
    init_metrics_to_zero(missed_gauge, metrics_state["MissedBlockProposals"])
    init_metrics_to_zero(empty_gauge, metrics_state["EmptyBlockProposals"])

    if reward_metrics:
        for key in metrics_state["RelayTotalRewards"]:
            total_rewards_gauge.labels(key).set(metrics_state["RelayTotalRewards"][key])

        for key in metrics_state["AvgRelayerRewards"]:
            avg_reward_gauge.labels(key).set(metrics_state["AvgRelayerRewards"][key])

        for key in metrics_state["UnknownRewardsBlocks"]:
            unknown_reward_blocks.labels(key).set(metrics_state["UnknownRewardsBlocks"][key])

        for key in metrics_state["TotalValidatorRewards"]:
            val_total_rewards_gauge.labels(key).set(metrics_state["TotalValidatorRewards"][key])

        for key in metrics_state["AvgValidatorRewards"]:
            val_avg_reward_gauge.labels(key).set(metrics_state["AvgValidatorRewards"][key])

        for key in metrics_state["ValUnknownRewardBlocks"]:
            val_unknown_reward_blocks.labels(key).set(metrics_state["ValUnknownRewardBlocks"][key])

def get_all_relays():
    """
    Gets a list of the relays in the config

    Returns:
    -----------
    list
        A list of the names of the relays
    """
    global relay_config

    relay_list = list(relay_config.keys())

    return relay_list

def init_metrics(last_slot):
    """
    Initialises the metrics to 0

    Parameters:
    -----------
    last_slot : int
        The number of the last slot
    """
    global keys, missed_gauge, empty_gauge, validator_totals_gauge, relay_blocks_gauge, total_relay_blocks_gauge, total_rewards_gauge, avg_reward_gauge, unknown_reward_blocks, data_obj, data, reward_metrics, val_total_rewards_gauge, val_avg_reward_gauge, val_unknown_reward_blocks

    # if it is the first time running script
    if last_slot == 0:
        relay_list = get_all_relays()
        for key in keys:
            # for each key, initialise missed/empty blocks metrics, and blocks proposed metric
            missed_gauge.labels(key).set(0) 
            empty_gauge.labels(key).set(0) 
            validator_totals_gauge.labels(key).set(0) 
            init_metric_state("ValidatorBlocksProposed", key)
            init_metric_state("EmptyBlockProposals", key)
            init_metric_state("MissedBlockProposals", key)

        for relay in relay_list:
            # for each relay, initialise the blocks proposed, total rewards, avg rewards, and blocks with unknown rewards metrics 
            relay_blocks_gauge.labels(relay).set(0) 
            init_metric_state("RelayBlocksProposed", relay)
            total_relay_blocks_gauge.labels(relay).set(0)
            init_metric_state("TotalRelayBlocksProposed", relay)
            if reward_metrics:
                total_rewards_gauge.labels(relay).set(0)
                init_metric_state("RelayTotalRewards", relay)
                avg_reward_gauge.labels(relay).set(0)
                init_metric_state("AvgRelayerRewards", relay)
                unknown_reward_blocks.labels(relay).set(0)
                init_metric_state("UnknownRewardsBlocks", relay)

                # also initialise a separate total, average and unknown reward for the validators we are monitoring
                val_total_rewards_gauge.labels(relay).set(0)
                init_metric_state("TotalValidatorRewards", relay)
                val_avg_reward_gauge.labels(relay).set(0)
                init_metric_state("AvgValidatorRewards", relay)
                val_unknown_reward_blocks.labels(relay).set(0)
                init_metric_state("ValUnknownRewardBlocks", relay)
            
        # also create the metrics above for cases where we don't know who the relayer was or there was no relayer
        relay_blocks_gauge.labels("Unknown").set(0)
        init_metric_state("RelayBlocksProposed", "Unknown")
        total_relay_blocks_gauge.labels("Unknown").set(0)
        init_metric_state("TotalRelayBlocksProposed", "Unknown")
        if reward_metrics:
            total_rewards_gauge.labels("Unknown").set(0)
            init_metric_state("RelayTotalRewards", "Unknown")
            avg_reward_gauge.labels("Unknown").set(0)
            init_metric_state("AvgRelayerRewards", "Unknown")
            unknown_reward_blocks.labels("Unknown").set(0)
            init_metric_state("UnknownRewardsBlocks", "Unknown")
            val_total_rewards_gauge.labels("Unknown").set(0)
            init_metric_state("TotalValidatorRewards", "Unknown")
            val_avg_reward_gauge.labels("Unknown").set(0)
            init_metric_state("AvgValidatorRewards", "Unknown")
            val_unknown_reward_blocks.labels("Unknown").set(0)
            init_metric_state("ValUnknownRewardBlocks", "Unknown")
    else:
        # if it is not our first time, set the data_obj as data
        data_obj = data


def reward_extraction(slot=None, block=None) -> float:
    """
    Calculates rewards for a given slot

    Parameters:
    -----------
    slot : int
        The slot number to get the rewards for
    block : object
        The block json object obtained by requesting /eth/v2/beacon/blocks/{slot_number}

    Returns:
    -----------
    float
        The reward value in ETH
    """
    global config, parallel_requests

    if slot is None and block is None:
        print('ERR: At least one argument must be passed.')
    
    # if block was not passed, get it using the rpc
    if slot is not None and block is None:
        block = get_slot(slot)

    # calculate reward manually
    if parallel_requests:
        value = calculate_rewards_parallel(int(block['data']['message']['body']['execution_payload']['block_number']), eth1_rpc)
    else:
        value = calculate_rewards(int(block['data']['message']['body']['execution_payload']['block_number']), eth1_rpc)

    return value

def get_non_relayed_slot(slot):
    """
    Queries a beacon chain RPC manually for a slot that was not relayed through one of the relays we're monitoring
    Also calls rewards functions to get reward of slot

    Parameters:
    -----------
    slot : int
        The slot number of the non-relayed slot

    Returns:
    -----------
    object
        The non-relayed slot
    float
        The reward value of the slot in ETH
    """
    global config, relay_config, retries, reward_metrics, sync_committee_metrics

    # get the block using a beacon-chain RPC
    block = get_slot(slot)

    # by default, the relay value is unknown
    relay_value = "Unknown"
    
    # try to read the extra data to find out who the relayer is
    try:
        extra_data = block['data']['message']['body']['execution_payload']['extra_data']

        # if extra_data is 0x, it means it's empty
        if(extra_data != '0x'):
            # if not empty, decode
            extra_data_str = bytes.fromhex(extra_data[2:]).decode('utf-8', 'ignore')

            # common relayer extra_data
            if 'bloxroute' in extra_data_str.lower():
                relay_value = 'BloXroute Max Profit'
                print("INF: Matched "+extra_data_str+" with relay BloXroute Max Profit")
            elif 'illuminate dmocratize dstribute' in extra_data_str.lower() or 'illuminate democratize distribute' in extra_data_str.lower():
                relay_value = 'Flashbots'
                print("INF: Matched "+extra_data_str+" with relay Flashbots")
            else:
                # go through each relayer name
                for relay, url in relay_config.items():
                    # check if the name of the relayer or the url of the relayer are in the extra data string
                    if relay.lower() in extra_data_str.lower() or url.lower() in extra_data_str.lower():
                        # if they are, assign that relayer value
                        relay_value = relay
                        print("INF: Matched "+extra_data_str+" with relay "+relay)
                        break
        
        # get the validator public key
        proposer_index = block["data"]["message"]["proposer_index"]
        s = requests.Session()
        s.mount('http://', HTTPAdapter(max_retries=retries))
        validator = s.get(eth2_rpc+"/eth/v1/beacon/states/head/validators/"+str(proposer_index)).json()
        
        # if we're tracking sync committee participation, update metrics
        if sync_committee_metrics:
            update_sync_committee_performance(slot_data=block)

        # build the slot object
        data = {
            "slot": slot,
            "proposer": validator["data"]["validator"]["pubkey"],
            "relay": relay_value,
            "missed": False,
            "empty": len(block["data"]["message"]["body"]["execution_payload"]["transactions"]) == 0
        }
    except:
        # otherwise, block is missed / empty
        proposer = get_slot_proposer(slot)
        data = {
            "slot": slot,
            "proposer": proposer,
            "relay": relay_value,
            "missed": True,
            "empty": True
        }

    # if slot is empty / missed there are no rewards
    if data["empty"] or data["missed"] or not reward_metrics:
        return data, -1
    
    if reward_metrics:
        # otherwise calculate rewards
        value = reward_extraction(block=block)

    return data, value

def get_payloads(relay):
    """
    Queries the relayer for payloads / slots

    Parameters:
    -----------
    relay : str
        The name of the relayer to query

    Returns:
    -----------
    list
        List of slots with the following structure:
        "slot": <num>,
        "parent_hash": <hash>,
        "block_hash": <hash>,
        "builder_pubkey": <hex_pub_key>,
        "proposer_pubkey": <hex_pub_key>,
        "proposer_fee_recipient": <hex_address>,
        "gas_limit": <num>,
        "gas_used": <num>,
        "value": <num>
        "relay": <str>
    """
    global relay_config, slots_limit, retries

    print("Requesting Relay: "+relay)

    # initialise list of slots
    slots = []
    success = True

    # try to request relayer
    try:
        s = requests.Session()
        s.mount('http://', HTTPAdapter(max_retries=retries))
        slots = s.get(relay_config[relay]+"/relay/v1/data/bidtraces/proposer_payload_delivered?limit="+str(slots_limit), timeout=10)
        slots.raise_for_status()
    except requests.exceptions.RequestException as e:
        print("Request failed")
        success = False
    
    if(success):
        # if request was successful
        slots = slots.json()
        print("Request completed.")

        # convert strings to ints
        for slot in slots:
            for key in slot:
                if (key in ['slot', 'gas_limit', 'gas_used', 'value']):
                    slot[key] = int(slot[key])
        
        # adding "relay" key
        for slot in slots:
            slot['relay'] = relay
    else:
        # if request failed, return empty list
        slots = []
    
    return slots

def get_all_payloads():
    """
    Calls get_payloads() function for all the relays, to get a complete list of slots

    Returns:
    -----------
    list
        List of ordered slots with the same structure as in get_payloads()
    """

    global relay_config, slots_limit

    # initialise list of payloads
    payloads = []

    # get payloads of each relay
    for relay, _ in relay_config.items():
        res = get_payloads(relay)

        # concatenate payloads into one list
        for payload in res:
            payloads.append(payload)

    # sort by slot number
    payloads = sorted(payloads, key=lambda d: d['slot'])

    # keep only last x slots
    payloads = payloads[-slots_limit:]

    return payloads

def get_all_payloads_parallel():
    """
    Performs parallel requests to relays to get their payloads

    Returns:
    -----------
    list
        List of ordered slots with the same structure as in get_payloads()
    """
    global relay_config, slots_limit, retries

    class Worker(Thread):
        """
        A class used to represent a worker thread

        Attributes:
        -----------
        queue : Queue
            Queue of relay names and endpoints to query
        results : list[list[dict]]
            List of lists of payloads of the relays
        
        Methods:
        --------
        run
            Performs a request to the relay to get the payloads
        """
        def __init__(self, ep_queue):
            """
            Parameters:
            -----------
            ep_queue : Queue
                The queue where dicts containing the relay names and endpoints will be placed
            """
            Thread.__init__(self)
            self.queue = ep_queue
            self.results = []

        def run(self):
            """
            Performs a request to the relay, and gets its payloads

            Returns:
            --------
            list
                The payloads of that relay
            """
            while True:
                # get new relay to request
                relay = self.queue.get()

                if relay['endpoint'] == "":
                    # an empty string is a signal to stop
                    break
                try:
                    # start a new session - so we can attempt requests multiple times
                    s = requests.Session()

                    # specify details to retry
                    s.mount('http://', HTTPAdapter(max_retries=retries))

                    # try the request
                    slots = s.get(relay['endpoint']+"/relay/v1/data/bidtraces/proposer_payload_delivered?limit="+str(slots_limit), timeout=10)
                    slots.raise_for_status()

                    # convert to json
                    slots = slots.json()
                    
                    # convert strings to ints
                    for slot in slots:
                        for key in slot:
                            if (key in ['slot', 'gas_limit', 'gas_used', 'value']):
                                slot[key] = int(slot[key])
                    
                    # adding "relay" key
                    for slot in slots:
                        slot['relay'] = relay['name']

                    # append to the list of results
                    self.results.append(slots)

                    # notify queue that the current task is done
                    print('INF: Successfully got payloads from relay "'+relay['name']+'".')
                    self.queue.task_done()
                except requests.exceptions.RequestException:
                    # if the request failed, we cannot do anything
                    print('WARN: Failed to get payloads from relay "'+relay['name']+'".')
                    self.results.append([])
                    self.queue.task_done()

    # create a worker per relay
    num_workers = len(relay_config)
    q = Queue()

    # add each relay in the queue
    for key, value in relay_config.items():
        q.put({
            'name': key,
            'endpoint': value
        })

    # workers don't stop until they receive an empty string
    for _ in range(num_workers * 2):
        q.put({
            'name': "",
            'endpoint': ""
        })

    # create workers
    workers = []

    # start the workers
    for _ in range(num_workers):
        worker = Worker(q)
        worker.start()
        workers.append(worker)
    
    # wait for all the workers to be done
    for worker in workers:
        worker.join()

    # get the results
    results = []
    for worker in workers:
        for list in worker.results:
            for payload in list:
                results.append(payload)
        
    # sort by slot number
    results = sorted(results, key=lambda d: d['slot'])

    # keep only the last x slots
    results = results[-slots_limit:]

    return results

def main(options: dict):
    """
    Performs all the functions in a loop and sleeps for 20s

    Parameters:
    -----------
    options : dict
        The CLI options (or from config.json) that configure the script
    """
    # defining global variables
    global data_obj, data, keys, eth1_rpc, eth2_rpc, slots_limit, reward_metrics, sync_committee_metrics, parallel_requests, relay_config, keys, validators_index_key_mappings, prev_sync_committee, curr_sync_committee, next_sync_committee, curr_sync_start_epoch, next_sync_start_epoch, upcoming_proposals, upcoming_sync_committee, retries, next_sync_updated

    # defining global variables for metrics
    global relay_blocks_gauge, validator_totals_gauge, missed_gauge, empty_gauge, total_relay_blocks_gauge, total_rewards_gauge, avg_reward_gauge, unknown_reward_blocks,val_total_rewards_gauge, val_avg_reward_gauge, val_unknown_reward_blocks, val_sync_participated_gauge, val_sync_missed_gauge, current_sync_committee_epoch_gauge, upcoming_block_prop_gauge, upcoming_sync_comm_part_gauge

    # set the database path global variable
    set_db_path(options['db'])

    # initialise data object to hold slots and metrics
    data_obj = {
        "last_slot": 0,
        "slots": [],
        "latest_metrics": {
            "RelayBlocksProposed": {},
            "TotalRelayBlocksProposed": {},
            "RelayTotalRewards": {},
            "AvgRelayerRewards": {},
            "UnknownRewardsBlocks": {},
            "ValidatorBlocksProposed": {},
            "MissedBlockProposals": {},
            "EmptyBlockProposals": {},
            "TotalValidatorRewards": {},
            "AvgValidatorRewards": {},
            "ValUnknownRewardBlocks": {}
        }
    }

    # variable to get last x slots from relayers
    slots_limit = 100

    # declare execution and consensus layer endpoints
    eth1_rpc = options['eth1_rpc']
    eth2_rpc = options['eth2_rpc']

    # are we tracking rewards?
    reward_metrics = options['rewards']

    # are we tracking sync committee participation?
    sync_committee_metrics = options["sync_committee"]

    if reward_metrics:
        # should requests to the ETH1 RPC be parallel?
        parallel_requests = options["eth1_parallel"]

    # open config of relay names and endpoints
    f = open(options['relay_config'])
    relay_config = json.load(f)

    # check if we have a db
    if isfile(options['db']):
        data = update_db(keys, relay_config)
    else:
        data = initialise_db(keys, relay_config)

    # check whether we are to continue from the last slot in the database or not
    if options['last_slot'] != 0:
        data['last_slot'] = options['last_slot'] - 1

    # check if database is too old to continue from that point
    if data['last_slot'] != 0:
        result = check_duties(data['last_slot'])
        if result == 0:
            pass
        else:
            if result != -1:
                raise Exception("Last slot in database is too old to proceed from. You can start from slot "+str(result+32)+" or higher.")
            else:
                raise Exception("Last slot in database is too old to proceed from.")

    # load metrics
    latest_metrics = data["latest_metrics"]
    last_slot = data["last_slot"]

    if sync_committee_metrics:
        # check if we have added the validator index column in the validators' table
        if not validator_index_exists():
            # if validator index table is not present, then we have to create and fill column
            print("INF: Fetching validator indexes, this process might take a while depending on your RPC client and whether parallel requests are enabled.")
            if options["eth2_parallel"]:
                insert_validator_indexes(get_validator_indexes_parallel(keys))
            else:
                insert_validator_indexes(get_validator_indexes(keys))
            print("INF: Validator indexes gathered and stored in database.")
        else:
            # if we have the validator index column, check that we have the validator index for ALL validators in the db
            vals_without_index = get_validators_without_indexes()

            if len(vals_without_index) > 0:
                # get the validator indexes for those without index
                print("INF: Fetching validator indexes for "+str(len(vals_without_index))+" validators. This process might take a while depending on your RPC client and whether parallel requests are enabled.")
                if options["eth2_parallel"]:
                    insert_validator_indexes(get_validator_indexes_parallel(vals_without_index))
                else:
                    insert_validator_indexes(get_validator_indexes(vals_without_index))
                print("INF: Validator indexes gathered and stored in database.")

        # store validator indexes - public key mappings
        validators_index_key_mappings = get_validator_indexes_pub_key_mappings()

        # keeping track of sync committees
        prev_sync_committee = {}
        curr_sync_committee = {}
        next_sync_committee = {}

        # also keep track of when the current committee starts and ends
        curr_sync_start_epoch = 0
        next_sync_start_epoch = 0

        # create a global variable for holding future sync committee participations
        upcoming_sync_committee = []

    # create a global variable for holding future block proposals
    upcoming_proposals = []

    # for retrying requests
    retries = Retry(total=10, backoff_factor=0.005, status_forcelist=[500, 503, 504], allowed_methods=frozenset(['GET', 'POST']))

    # initialise http server & collector
    start_http_server(options["port"])
    collector = CollectorRegistry()

    # initialise the different metrics
    relay_blocks_gauge = Gauge("RelayBlocksProposed", 'Blocks Proposed by each relay', ["relay"], registry=collector)
    validator_totals_gauge = Gauge("ValidatorBlocksProposed", 'Blocks Proposed by each validator', ["public_key"], registry=collector)
    missed_gauge = Gauge("MissedBlockProposals", 'Missed Blocks Proposals by each validator', ["public_key"], registry=collector)
    empty_gauge = Gauge("EmptyBlockProposals", 'Empty Blocks Proposals by each validator', ["public_key"], registry=collector)
    total_relay_blocks_gauge = Gauge("TotalRelayBlocksProposed", 'Total number of blocks relayed by each relay', ["relay"], registry=collector)
    active_keys_gauge = Gauge("ActivePubKeys", 'Total number of keys that are currently being monitored', ["active"], registry=collector)

    # initialise the active keys gauge
    active_keys_gauge.labels("yes").set(len(validators_index_key_mappings.keys()))
    active_keys_gauge.labels("no").set(len(keys) - len(validators_index_key_mappings.keys()))

    # reward metrics
    if reward_metrics:
        total_rewards_gauge = Gauge("RelayTotalRewards", 'Total Rewards by each relayer', ["relay"], registry=collector)
        avg_reward_gauge = Gauge("AvgRelayerRewards", 'Average Reward per block by each relayer', ["relay"], registry=collector)
        unknown_reward_blocks = Gauge("UnknownRewardBlocks", 'Total Number of blocks with an unknown reward value', ["relay"], registry=collector)

        val_total_rewards_gauge = Gauge("TotalValidatorRewards", 'Total Rewards by each relayer generated by the validators we are monitoring', ["relay"], registry=collector)
        val_avg_reward_gauge = Gauge("AvgValidatorRewards", 'Average Reward per block by each realyer by the validators we are monitoring', ["relay"], registry=collector)
        val_unknown_reward_blocks = Gauge("ValUnknownRewardBlocks", 'Total Number of blocks with an unknown reward proposed by the validators we are monitoring', ["relay"], registry=collector)

    # committee sync metrics
    if sync_committee_metrics:
        val_sync_participated_gauge = Gauge("ValidatorSyncParticipated", 'Total number of participations in current sync committee by validator.', ["public_key", "epoch"], registry=collector)
        val_sync_missed_gauge = Gauge("ValidatorSyncMissed", 'Total number of missed participations in current sync committee by validator.', ["public_key", "epoch"], registry=collector)
        current_sync_committee_epoch_gauge = Gauge("CurrentSyncCommitteeEpoch", 'Label contains the epoch at which the committee sync started. Value is 1 if it is the current committee and 0 otherwise.', ["epoch"], registry=collector)
        # initialise upcoming sync committee participations metrics if sync committee metrics are enabled
        upcoming_sync_comm_part_gauge = Gauge("UpcomingSyncCommitteeParticipations", 'The epoch at which the validator will start participating in the sync committee for 256 epochs.', ["public_key"], registry=collector)

    # initialise upcoming block proposals metric
    upcoming_block_prop_gauge = Gauge("UpcomingBlockProposal", 'The slot number at which the validator is proposing a block.', ["public_key"], registry=collector)

    # initialise current slot metric
    current_slot_gauge = Gauge("CurrentSlotNumber", 'The latest slot number.', registry=collector)

    REGISTRY.register(collector)

    # initialise metric values
    init_metrics(last_slot)
    load_metrics(latest_metrics)

    while True: 
        # get all the slots from all the relays
        slots = get_all_payloads_parallel()

        # update the current slot number
        if len(slots) > 0:
            current_slot_gauge.set(slots[-1]['slot'])

        for slot in slots:
            if slot["slot"] > data_obj["last_slot"]:
                # first check that we have initialised sync committee variables
                if sync_committee_metrics:
                    if curr_sync_start_epoch == 0:
                        curr_slot = data_obj["last_slot"] + 1 if (data_obj["last_slot"] != 0 and slot["slot"] != data_obj["last_slot"] + 1) else slot["slot"]
                        check_sync_committee(list(validators_index_key_mappings.keys()), curr_slot)

                        # see if we have any values in the database for the past committee
                        participated, missed = get_sync_committee_performance_between_slots((curr_sync_start_epoch-256)*32, (curr_sync_start_epoch*32)-1)

                        if participated != {}:
                            set_sync_committee_metrics(participated, missed, curr_sync_start_epoch-256)

                        # see if we have any values in the database for the current committee
                        participated, missed = get_sync_committee_performance_between_slots(curr_sync_start_epoch*32, (next_sync_start_epoch*32)-1)

                        if participated != {}:
                            set_sync_committee_metrics(participated, missed, curr_sync_start_epoch)
                    if not next_sync_updated and slot["slot"] > ((curr_sync_start_epoch * 32) + 200):
                        # if 20 minutes have passed since the start of the current sync committee, it should be safe to query the rpc for the next sync committee
                        update_next_sync_committee_metrics(list(validators_index_key_mappings.keys()))


                # if we skipped slots - get data manually through rpc
                if data_obj["last_slot"] != 0 and slot["slot"] != data_obj["last_slot"] + 1:
                    # get the missing slots
                    missing_slot_count = slot["slot"] - data_obj["last_slot"]
                    for i in range(missing_slot_count - 1):
                        missing_slot = data_obj["last_slot"]+i+1
                        print('INF: Slot '+str(missing_slot)+' not found in any relays'' payload. Requesting consensus layer endpoint.')

                        # check if we've reached the end epoch and need to update variables
                        if sync_committee_metrics:
                            if missing_slot == next_sync_start_epoch * 32 or missing_slot > next_sync_start_epoch * 32:
                                check_sync_committee(list(validators_index_key_mappings.keys()), missing_slot)

                        # get slot and reward value, and update metrics
                        data, reward = get_non_relayed_slot(missing_slot)
                        if reward_metrics:
                            print('INF: Slot: '+str(missing_slot)+'\tReward: '+str(reward))
                        else:
                            print('INF: Slot: '+str(missing_slot))
                        update_metrics(data, reward)
                        insert_new_slot(data['slot'], data['proposer'], data['relay'], data['missed'], data['empty'], reward)

                        if reward_metrics:
                            # update reward metrics and append slot to data_obj
                            update_reward_metrics(data["relay"], reward)
                        data_obj["slots"].append(data)

                # check if we've reached the end epoch and need to update variables
                if sync_committee_metrics:
                    if slot["slot"] == next_sync_start_epoch * 32 or slot["slot"] > next_sync_start_epoch * 32:
                        check_sync_committee(list(validators_index_key_mappings.keys()), slot["slot"])

                # if slot is in relayer data, fill in data
                data = {
                    "slot": slot["slot"],
                    "proposer": slot["proposer_pubkey"] if "proposer_pubkey" in slot else slot["proposer"],
                    "relay": slot["relay"],
                    "missed": False,
                    "empty": False if (slot["value"] / 1000000000000000000) > 0.0 else check_if_empty(slot["slot"])
                }

                # if we're tracking sync committee participation, update metrics
                if sync_committee_metrics:
                    update_sync_committee_performance(slot=slot["slot"])

                # reward value is in slot data, divide to get ETH value
                reward = slot["value"] / 1000000000000000000
                print('INF: Slot: '+str(slot["slot"])+'\tReward: '+str(reward))
                data_obj["slots"].append(data)
                data_obj["last_slot"] = slot["slot"]

                insert_new_slot(data['slot'], data['proposer'], data['relay'], data['missed'], data['empty'], reward)

                # update metrics and reward metrics
                update_metrics(data, reward)
                
                if reward_metrics:
                    update_reward_metrics(data["relay"], reward)

        update_upcoming_block_proposals(data_obj["last_slot"])
        update_block_prop_metrics(data_obj["last_slot"])

        # if pruning is enabled, then prune
        if options['prune']:
            prune_db(options['keep_last_slots'])

        # sleep for 20s
        time.sleep(20)

if __name__ == "__main__":
    
    # get command-line options
    arguments = sys.argv[1:]

    # ensure that the correct options were passed
    try:
        opts, args = getopt.getopt(arguments, "hc:v", ["help", "config=", "version", "relay_config=", "port=", "pubkeys_file=", "pubkeys=", "eth1_rpc=", "eth1_parallel", "eth2_rpc=", "eth2_parallel", "rewards", "sync_committee", "prune", "keep_last_slots=", "last_slot="])
    except Exception as e:
        print("ERR: Incorrect options passed: "+str(e))
        exit()

    # show a warning when options that did not require a value were given one
    if len(args) > 0:
        print('WARN: Some command-line options that did not require a value were given a value. As a result, the following arguments will be ignored:', end=' ')
        print(*args, sep=", ", end=". ")
        print('To fix this, remove the value given to the "'+opts[-1][0]+'" option: "'+args[0]+'".')

    # declare a dict to hold the options
    options = {
        'config': None,
        'relay_config': None,
        'db': None,
        'port': None,
        'pubkeys_file': None,
        'pubkeys': None,
        'eth1_rpc': None,
        'eth1_parallel': None,
        'eth2_rpc': None,
        'eth2_parallel': None,
        'rewards': None,
        'sync_committee': None,
        'prune': None,
        'keep_last_slots': None,
        'last_slot': None
    }
    
    # iterate over the arguments and perform an action based on each
    for opt, arg in opts:
        if opt == '-h' or opt == '--help':
            print("""Options and arguments:

HELP
-h --help\t\t:  print this help message
-v --version\t\t:  outputs the version of the tool

CONFIG
-c --config\t\t:  the path to config.json (optional if options are provided through command-line)
--relay_config\t\t:  the path to the relay config, containing the names and endpoints of the relays to query
--port\t\t\t:  the port on which the Prometheus metrics will be published
--pubkeys_file\t\t:  the path to a comma-separated list of the public keys of the validators that the script will monitor (optional if --pubkeys is used)
--pubkeys\t\t:  a string of comma-separated public keys of the validators that the script will monitor (optional if --pubkeys_file is used)

ENDPOINTS
--eth1_rpc\t\t:  an endpoint of an execution-layer node that will be used for reward metrics (not needed if reward metrics are not enabled)
--eth1_parallel\t\t:  enables parallel requests to the execution-layer node
--eth2_rpc\t\t:  an endpoint of a consensus-layer node
--eth2_parallel\t\t:  enables parallel requests to the consensus-layer node

FEATURES
--rewards\t\t:  enables reward metrics
--sync_committee\t:  enables sync committee participation metrics
--prune\t\t\t:  enable pruning of the slots table
--keep_last_slots\t:  how many slots to keep if pruning is enabled, defaults to the last 100
--last_slot\t\t:  the slot to attempt to continue (or start) syncing from. Defaults to 0 which is the (current slot - 100) or the last slot in the database""")
            exit()
        elif opt == '-c' or opt == '--config':
            if not exists(arg):
                print('ERR: Path passed for --config "'+str(arg)+'" is not valid, or the file does not exist.')
                exit()
            options['config'] = arg
        elif opt == '-v' or opt == '--version':
            print("ETH Block Proposal Monitor v0.3")
            exit()
        elif opt == '--relay_config':
            if not exists(arg):
                print('ERR: Path passed for --relay_config "'+str(arg)+'" is not valid, or the file does not exist.')
                exit()
            options['relay_config'] = arg
        elif opt == '--port':
            try:
                options['port'] = int(arg)
            except:
                print('ERR: Port number passed for --port "'+str(arg)+'" is not a valid integer.')
                exit()
        elif opt == '--pubkeys_file':
            if not exists(arg):
                print('ERR: Path passed for --pubkeys_file "'+str(arg)+'" is not valid, or the file does not exist.')
                exit()
            options['pubkeys_file'] = arg
        elif opt == '--pubkeys':
            options['pubkeys'] = arg
        elif opt == '--eth1_rpc':
            if not check_endpoint_validity_eth1(arg):
                print('ERR: Endpoint passed for --eth1_rpc "'+str(arg)+'" did not return a successful response. Ensure the endpoint is correct, and that the node is a fully-synced execution layer node.')
                exit()
            options['eth1_rpc'] = arg
        elif opt == '--eth1_parallel':
            options['eth1_parallel'] = True
        elif opt == '--eth2_rpc':
            if not check_endpoint_validity_eth2(arg):
                print('ERR: Endpoint passed for --eth2_rpc "'+str(arg)+'" did not return a successful response. Ensure the endpoint is correct, and that the node is a fully-synced consensus layer node that supports the Beacon Node API spec (https://ethereum.github.io/beacon-APIs/).')
                exit()
            options['eth2_rpc'] = arg
        elif opt == '--eth2_parallel':
            options['eth2_parallel'] = True
        elif opt == '--rewards':
            options['rewards'] = True
        elif opt == '--sync_committee':
            options['sync_committee'] = True
        elif opt == '--prune':
            options['prune'] = True
        elif opt == '--keep_last_slots':
            try:
                options['keep_last_slots'] = int(arg)
            except:
                print('ERR: Value passed for --keep_last_slots "'+str(arg)+'" is not a valid integer.')
                exit()
        elif opt == '--last_slot':
            try:
                options['last_slot'] = int(arg)
            except:
                print('ERR: Value passed for --last_slot "'+str(arg)+'" is not a valid integer.')
                exit()
        elif opt == '--db':
            if not exists(arg):
                print('ERR: Path passed for --db "'+str(arg)+'" is not valid, or the file does not exist.')
                exit()
            options['db'] = arg

    # in case a config file was passed, parse it
    if options['config'] is not None:
        options = read_config_update_options(options)
    
    # change any options which were not passed to the default value
    options = none_to_default(options)
    
    global keys

    # read the keys, either from the command-line option or from file
    if options['pubkeys'] is not None:
        keys = read_keys_from_str(options['pubkeys'])
    else:
        keys = read_keys_from_file(options['pubkeys_file'])

    # call the main function and pass all the options
    main(options)